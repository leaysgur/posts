{
  "title": "フロントエンド x RTC界隈の最近とこれから",
  "html": "<p>フロントエンドエンジニアからみる、この界隈で今どんなIssueが話題になってるのかと、この先どういう動きがありそうかについて。</p><p>そこまで自分に先見の明があるとも思ってないけど、アウトプットしておかないと忘れてしまいそうなので・・。</p><p>ちなみにここでいうフロントエンドは、いわゆるブラウザとかJavaScriptのAPIのことです。<br />\nプロトコル的な側面はそこまで詳しくないのであまり触れません。<br />\n<br />\n</p>\n\n<div class=\"section\">\n    <h3>WebRTC 1.0</h3>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/w3c/webrtc-pc\">GitHub - w3c/webrtc-pc: WebRTC 1.0 API</a></p>\n\n    </blockquote>\n<p>まず、RTCといえばズバリのWebRTCから。</p><p>昨年末にWDからCRへ格上げということで、もうAPIが激変したりはしない・・はず。<br />\n実際のところ、ここ半年くらい大きな対応した覚えがないです。（WebRTCそのものを実装してる人は、地味にいろいろ対応してると思うけど）</p><p>ガワのAPIという観点でいうと、最近はもうユースケースを掘り下げていくフェーズというよりか、仕様としてのつじつま合わせやら、こんなときどうなるの？っていうコーナーケースへのIssueが多い印象。</p><p>たとえば通信中のノートPCをパタンって閉じたら、その通信はどうなる？とか、APIとしてこういうケースは可能になってるけど、その場合の状態遷移はどうあるべきか？とか。</p><p>JSのAPIネタでいうと、Perfect Negotiationの一連APIたちが実装された暁には、何かしら対応してみてもよいかもしれない。</p>\n\n    <blockquote>\n        <p><a href=\"https://lealog.hateblo.jp/entry/2019/12/05/095721\">WebRTC&#x306E;Perfect negotiation&#x306B;&#x3064;&#x3044;&#x3066; - console.lealog();</a></p>\n\n    </blockquote>\n<p>まあ、シグナリングのグレアは他にも回避方法あるし、今さら・・とは思う。</p><p>（そんなことよりFirefoxに`setConfiguration()`実装してほしい。）</p>\n\n<div class=\"section\">\n    <h4>蛇足: Unified-plan</h4>\n    <p>この記事を書いてて思い出したネタ。</p>\n\n    <blockquote>\n        <p><a href=\"https://webrtchacks.com/is-everyone-switching-to-unified-plan/\">Is everyone switching to Unified Plan? - webrtcHacks</a></p>\n\n    </blockquote>\n<p>Unified-planってそういえばどうなったっけ・・みんなちゃんと使ってる？恩恵受けてる？っていうやつ。</p><p>まぁその記事としても、Chromeの中の人たちとしても、どうやらあんましらしい。</p>\n\n    <blockquote>\n        <p><a href=\"https://bugs.chromium.org/p/chromium/issues/detail?id=857004\">857004 - chromium - An open-source project to help move the web forward. - Monorail</a></p>\n\n    </blockquote>\n<p>まあ実際は1トランスポートあたり1audio+1video以上やりとりしたいユースケースってあまり思いつかん + 別に2トランスポートでなんとかなるので、ほんとシビアな仕様やったんやなとは思う・・。</p><p>セマンティクスとしてはこっちのほうがシュッとしてると思うけど。</p>\n\n</div>\n<div class=\"section\">\n    <h4>webrtc-extensions</h4>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/w3c/webrtc-extensions\">GitHub - w3c/webrtc-extensions: A repository for &quot;WebRTC 1.1+&quot; features</a></p>\n\n    </blockquote>\n<p>そんな1.0のスコープから漏れた機能群は、だいたい拡張仕様って扱いになってます。</p><p>たとえばTPACでも話題になってた`RTCRtpReceiver`の`playoutDelay`。<br />\nいまだと受け取ったメディアはASAPで再生されるけど、そこに恣意的な遅延をつけられるようにしてちょっとバッファしたい・・とか。</p><p>あとはHWエンコードできるコーデックがAPIで事前にわかると嬉しいよね、とか。</p><p>まあこの界隈は論者が限られてるので、全般的にアクティブではないです。<br />\nそういう意味ではNextVersionに関しても、ここのところ下火。</p>\n\n    <blockquote>\n        <p><a href=\"https://github.com/w3c/webrtc-nv-use-cases\">GitHub - w3c/webrtc-nv-use-cases: Use cases for WebRTC NV</a></p>\n\n    </blockquote>\n\n</div>\n<div class=\"section\">\n    <h4>Statistics</h4>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/w3c/webrtc-stats\">GitHub - w3c/webrtc-stats: WebRTC Statistics</a></p>\n\n    </blockquote>\n<p>おなじみ`getStats()`で取れるレポートあれこれについて。<br />\nこれも年明けにCRになり、いろいろ頑張ってるところ。</p><p>ただ実際のところはブラウザ差異がまったく埋まってなくて、我々としてはもう一声といった感じ。</p>\n\n    <blockquote>\n        <p><a href=\"https://github.com/leader22/webrtc-stats-impl-status\">GitHub - leader22/webrtc-stats-impl-status</a></p>\n\n    </blockquote>\n<p>ここに現時点の最新ブラウザでの実装差異をチマチマ集めてますのでご参照をば。</p><p>ただこれで定量的な値が取れたとて、実際は手札（そういう細かいAPI）が存在しなくてほとんどアクションできないんですよね〜。</p>\n\n</div>\n</div>\n<div class=\"section\">\n    <h3>Media Capture and Streams</h3>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/w3c/mediacapture-main\">GitHub - w3c/mediacapture-main: Media Capture and Streams specification (aka getUserMedia)</a></p>\n\n    </blockquote>\n<p>おなじみの`getUserMedia()`とか、`enumerateDevices()`とか。</p><p>こちらもCRながら、セマンティクスの問題とプライバシー方面の議論が入り混じって大乱闘状態。</p><p>すごくかいつまんでトピックを並べると、</p>\n\n<ul>\n<li>デバイス機能の詳細はFingerprintになるから見せられないよ</li>\n<li>`{ video: true }`ですべてのデバイスの許可取れるのおかしくない？</li>\n<li>`getDisplayMedia()`みたいに、ブラウザがピッカー持つべきでは？\n<ul>\n<li>`{ video: true, semantics: \"user-chooses\" }`的な</li>\n</ul></li>\n<li>そもそも許可なしでデバイス一覧見れるのがおかしくない？</li>\n<li>一口にaudioって言っても、チャット用と演説用とで性質違うしその旨も指定したいです\n<ul>\n<li><a href=\"https://github.com/w3c/mst-content-hint\">https://github.com/w3c/mst-content-hint</a></li>\n</ul></li>\n<li>etc..</li>\n</ul><p>`enumerateDevices()`もついこの間も変更があったところなので、これらに関してはまだこれからも変わりそうやなーという感じ。</p><p>ここに関しては、PSAが出たらさっさと検証するしかなさそう・・。</p>\n\n</div>\n<div class=\"section\">\n    <h3>WebTransport</h3>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/WICG/web-transport\">GitHub - WICG/web-transport: WebTransport is a web API for flexible data transport</a></p>\n\n    </blockquote>\n<p>ここからはちょっと先の話題。</p><p>サーバーとクライアント間の双方向で低遅延なやり取りがしたい場合の選択肢として、現状ではWebSocketかWebRTCのDataChannelかが主な選択肢になるはず。</p><p>ただWebSocketだとHoLBでパフォーマンスの問題があるし、WebRTCだとICEいらないしDTLSでSCTPなので実装が大変+そもそもサバクラで使いにくい。</p><p>ちょうどいいUDPベースのWebSocketライクなやつが欲しい・・ということで生まれたのが、QUICの上で動くWebTransport。</p><p>QUICとか、プロトコルの詳細については、別に詳しい人がいると思うので気になった人は調べてみてください。<br />\nドラフトを訳したやつがあるのでいちおう置いておきます。</p>\n\n    <blockquote>\n        <p><a href=\"https://github.com/leader22/webtransport-rfcs\">GitHub - leader22/webtransport-rfcs</a></p>\n\n    </blockquote>\n<p>たとえばクラウドゲーミングだと、クライアントからサーバーにはユーザー操作をデータで送って、サーバーからは結果がメディアで返ってくるのでそれを描画する感じ。</p><p>APIとしては`whatwg/streams`のそれ。</p>\n<pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synComment\">// Example of sending unreliable game state to server using QUIC datagrams</span>\n\n<span class=\"synStatement\">const</span> transport = <span class=\"synStatement\">new</span> QuicTransport(<span class=\"synConstant\">'example.com'</span>, 10001);\n<span class=\"synStatement\">const</span> datagramWriter = transport.sendDatagrams().getWriter();\n\nsetInterval(() =&gt; <span class=\"synIdentifier\">{</span>\n  <span class=\"synStatement\">const</span> message = getSerializedGameState();\n  datagramWriter.write(message);\n<span class=\"synIdentifier\">}</span>, 100);\n</pre><p>`ReadableStream`しかり`WritableStream`しかりをよしなに使うことになるはずで、このあたりのAPIは慣れが必要そう。</p><p>ただChromeですらまだIn developmentなので、まっだまだ先の話です。</p>\n\n<div class=\"section\">\n    <h4>WebRTC-QUIC</h4>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/w3c/webrtc-quic\">GitHub - w3c/webrtc-quic: Interface to create and manage QUIC streams</a></p>\n\n    </blockquote>\n<p>ChromeではOriginTrialまでしてたけど、最近はWebTransportのこともあってかやや下火。<br />\nというか、気付けばWebTransportありきの仕様になってる感。</p><p>クライアントP2PでのWebRTCは、しばらく今のままって感じですかねー。</p>\n\n</div>\n</div>\n<div class=\"section\">\n    <h3>WebSocketStream</h3>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/ricea/websocketstream-explainer\">GitHub - ricea/websocketstream-explainer: Explainer for the WebSocketStream JavaScript API</a></p>\n\n    </blockquote>\n<p>WebSocketで`Stream`のAPIを使えるようにして、BackPressureに対応したモダンな書き味にしたいよねというプロポーザル。</p>\n<pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synStatement\">const</span> wss = <span class=\"synStatement\">new</span> WebSocketStream(url);\n<span class=\"synStatement\">const</span> <span class=\"synIdentifier\">{</span> readable <span class=\"synIdentifier\">}</span> = await wss.connection;\n\n<span class=\"synStatement\">const</span> reader = readable.getReader();\n<span class=\"synStatement\">while</span> (<span class=\"synConstant\">true</span>) <span class=\"synIdentifier\">{</span>\n  <span class=\"synStatement\">const</span> <span class=\"synIdentifier\">{</span> value, done <span class=\"synIdentifier\">}</span> = await reader.read();\n  <span class=\"synStatement\">if</span> (done) <span class=\"synStatement\">break</span>;\n\n  await process(value);\n<span class=\"synIdentifier\">}</span>\ndone();\n</pre><p>こちらもモノはおなじく`whatwg/streams`ですね。</p><p>QUIC上で動くWebTransportのほうが上位互換ではあるけど、UDPが通らない環境とかもあると思うし、WebTransportがくるまでのつなぎとしての狙いもありそう。</p><p>ともあれデータをいい感じに流す土管は揃い踏みした感あるので、あとは何をやり取りするか。</p><p>ChromeCanaryではもう動くので、WebTransportよりは早そうではある。</p>\n\n</div>\n<div class=\"section\">\n    <h3>WebCodecs</h3>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/WICG/web-codecs\">GitHub - WICG/web-codecs: WebCodecs is a flexible web API for encoding and decoding audio and video</a></p>\n\n    </blockquote>\n<p>いい感じの土管ができたら、そのデータを描画する部分のAPIがあるといいよね、ということで。</p><p>今もJS/WASMで自前エンコード・デコードすることはできるけど、それだとメモリ効率とかHWも有効利用できないし、そもそもブラウザに載ってるコーデックを再実装するのが無駄という話もあり。</p><p>WebRTCでも生のメディアには触れないし、やっぱあらゆるユースケースに対応するためには、コンポーネントを細かく切っていくしか無い世相を感じますね。</p>\n<pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synComment\">// Example of video rendering to Canvas for low-latency live streaming or cloud gaming</span>\n\n<span class=\"synStatement\">class</span> CanvasRendererSink <span class=\"synIdentifier\">{</span>\n  constructor(canvas) <span class=\"synIdentifier\">{</span>\n    <span class=\"synIdentifier\">this</span>._context = canvas.getContext(<span class=\"synConstant\">'bitmaprenderer'</span>);\n  <span class=\"synIdentifier\">}</span>\n\n  write(videoFrame) <span class=\"synIdentifier\">{</span>\n    _context.transferFromImageBitmap(videoFrame.image);\n    <span class=\"synStatement\">return</span> Promise.resolve();\n  <span class=\"synIdentifier\">}</span>\n<span class=\"synIdentifier\">}</span>\n\n<span class=\"synStatement\">const</span> canvas = <span class=\"synStatement\">document</span>.getElementById(<span class=\"synConstant\">&quot;canvas&quot;</span>);\n\n<span class=\"synStatement\">const</span> renderingStream = <span class=\"synStatement\">new</span> WritableStream(<span class=\"synStatement\">new</span> CanvasRendererSink(canvas));\n<span class=\"synStatement\">const</span> videoDecoder = <span class=\"synStatement\">new</span> VideoDecoder(<span class=\"synIdentifier\">{</span> codec: <span class=\"synConstant\">&quot;vp8&quot;</span> <span class=\"synIdentifier\">}</span> );\n\nencodedVideoStream.pipeThrough(videoDecoder).pipeTo(renderingStream);\n</pre><p>これもAPIとしては`whatwg/streams`のそれ（だいたい`TransformStream`）で、用途に応じていろいろ用意されるクラスを使い分けることになる想定。</p><p>これもIn developmentなやつ。</p>\n\n</div>\n<div class=\"section\">\n    <h3>Insertable Streams API for WebRTC</h3>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/alvestrand/webrtc-media-streams\">GitHub - alvestrand/webrtc-media-streams: Insertable Streams API for WebRTC</a></p>\n\n    </blockquote>\n<p>話は戻ってまたWebRTC。<br />\nこれもまだ単なるプロポーザルではあるけど、WebRTCでやり取りするメディアを手元で加工したいよねという話。</p>\n<pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synComment\">// それ用のフラグ</span>\n<span class=\"synStatement\">const</span> pc = <span class=\"synStatement\">new</span> RTCPeerConnection(<span class=\"synIdentifier\">{</span>\n  forceEncodedVideoInsertableStreams: <span class=\"synConstant\">true</span>,\n  forceEncodedAudioInsertableStreams: <span class=\"synConstant\">true</span>\n<span class=\"synIdentifier\">}</span>);\n\n<span class=\"synComment\">// TransformStream</span>\n<span class=\"synStatement\">const</span> senderTransform = <span class=\"synStatement\">new</span> TransformStream(<span class=\"synIdentifier\">{</span>\n  async transform(chunk, controller) <span class=\"synIdentifier\">{</span> <span class=\"synComment\">/* ... */</span> <span class=\"synIdentifier\">}</span>\n<span class=\"synIdentifier\">}</span>);\n\n<span class=\"synStatement\">const</span> videoSender = pc.addTrack(track, stream)\n<span class=\"synStatement\">const</span> senderStreams = videoSender.getEncodedVideoStreams();\n\nsenderStreams.readable\n  .pipeThrough(senderTransform)\n  .pipeTo(senderStreams.writable);\n</pre><p>これは先述のWebCodecsありきなコードになってるけど、今の時点でも有効なユースケースが実はある。</p><p>それが、このAPIを使って今話題のE2Eの暗号化を実現するサンプル。</p>\n\n    <blockquote>\n        <p><a href=\"https://webrtc.github.io/samples/src/content/peerconnection/endtoend-encryption/\">Peer connection end to end encryption</a></p>\n\n    </blockquote>\n<p>まだChromeのCanaryでしか動かないけど。</p><p>あとは受け取ったvideoのキーフレームをカウントするサンプルとかもレビュー中。</p>\n\n    <blockquote>\n        <p><a href=\"https://github.com/webrtc/samples/pull/1276\">Video analyzer by alvestrand &middot; Pull Request #1276 &middot; webrtc/samples &middot; GitHub</a></p>\n\n    </blockquote>\n<p>なんしか、画一的なやり方でメディアを加工できるようになるのはよいですね。</p>\n\n</div>\n<div class=\"section\">\n    <h3>フロントエンドエンジニアとして</h3>\n    <p>SDKを作る側としては、今後も仕様の動向やプロトコルそれ自体についてもある程度知っておく必要がありそう + APIとしては`Stream`に慣れておくとよいかも？</p><p>一般的なフロントエンドエンジニアがRTC系のことをやる場合は、基本的に何某かのSDKを使うはず。<br />\nなので、その背景のプロトコルやAPIを知っておく必要は実際ほぼないと思ってて、それよりもそのSDKの通信モデルやらAPIを熟知して、できること・できないことを判断できるようになっておくほうがよいのかなと思います。</p><p>とは言っても汎用性の高いSDKを選んだなら、自分で`Stream`経由で生メディアに触れることもあるかもしれんけど・・。</p>\n\n</div>"
}
