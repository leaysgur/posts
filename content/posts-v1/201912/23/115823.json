{
  "title": "WebAudioでの音声信号処理",
  "html": "\n    <blockquote>\n        <p><a href=\"https://lealog.hateblo.jp/entry/2019/12/16/103754\">WebAudio&#x3067;&#x306E;&#x97F3;&#x58F0;&#x4FE1;&#x53F7;&#x51E6;&#x7406; &#x301C;&#x5165;&#x9580;&#x4EE5;&#x524D;&#x301C; - console.lealog();</a></p>\n\n    </blockquote>\n<p>この内容を踏まえて、実際にコードを書いていく際のポイントなど。</p><p>2019年末の情報です。<br />\n<br />\n</p>\n\n<div class=\"section\">\n    <h3>AudioContext</h3>\n    <p>今も昔も、WebAudio APIを触るなら絶対に必要なやつ。</p>\n<pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synStatement\">const</span> ctx = <span class=\"synStatement\">new</span> AudioContext();\n</pre><p>基本的にはコレで万事よしと言いたいところですが、Safariは今でも`webkitAudioContext`とプレフィックスが必要。</p><p>あんま知られてないと思うけど、サンプリングレートの指定もできる。</p>\n<pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synStatement\">const</span> ctx = <span class=\"synStatement\">new</span> AudioContext(<span class=\"synIdentifier\">{</span> sampleRate: 8000 <span class=\"synIdentifier\">}</span>);\n</pre><p>ただしこれも、Safariでは動かない・・。</p>\n\n</div>\n<div class=\"section\">\n    <h3>PCMデータを得る</h3>\n    <p>2019年の末の選択肢としては2つ。</p>\n\n<ul>\n<li>ScriptProcessor</li>\n<li>AudioWorkletProcessor</li>\n</ul><p>それぞれ見てみる。</p>\n\n<div class=\"section\">\n    <h4>ScriptProcessor</h4>\n    \n<ul>\n<li>いわゆるデファクト\n<ul>\n<li>Chrome / Firefox / Safariで動く</li>\n</ul></li>\n<li>ただしメインスレッドで動くので、非推奨とされ仕様からは消された存在\n<ul>\n<li>正確には、コールバックがメインスレッドで呼ばれてしまう</li>\n</ul></li>\n</ul><pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synStatement\">const</span> ctx = <span class=\"synStatement\">new</span> AudioContext();\n\n<span class=\"synComment\">// bufferSize, numberOfInputChannels, numberOfOutputChannels</span>\n<span class=\"synStatement\">const</span> processorNode = ctx.createScriptProcessor(1024, 1, 1);\nprocessorNode.onaudioprocess = ev =&gt; <span class=\"synIdentifier\">{</span>\n  <span class=\"synStatement\">const</span> <span class=\"synIdentifier\">{</span> inputBuffer, outputBuffer <span class=\"synIdentifier\">}</span> = ev;\n\n  <span class=\"synComment\">// ここでinputBufferから各チャンネルを取り出す</span>\n  <span class=\"synComment\">// もちろん最初に指定したチャンネル数しかない</span>\n  <span class=\"synComment\">// それぞれは AudioBuffer というクラスになってる</span>\n  <span class=\"synComment\">// こうすると得られるサンプルは、Float32Array</span>\n  <span class=\"synStatement\">const</span> samples = inputBuffer.getChannelData(0);\n\n  <span class=\"synComment\">// 音声処理はここでやる</span>\n\n  <span class=\"synComment\">// 最終的にoutputBufferへ返す</span>\n  <span class=\"synComment\">// 単にbypassするならこう</span>\n  outputBuffer.getChannelData(0).set(samples);\n<span class=\"synIdentifier\">}</span>;\n\n\n<span class=\"synComment\">// IN</span>\nfooNode.connect(processorNode);\n<span class=\"synComment\">// OUT</span>\nprocessorNode.connect(ctx.destination);\n</pre><p>サンプリングレートに応じた頻度で、この`onaudioprocess`イベントが発火するようになってる。<br />\nなので`bufferSize`が`1024`で、`sampleRate`が`8000`の場合は、7回/秒くらいで呼ばれる。</p><p>ちなみに量子化ビット数は`Float32Array`なので32bitと、中々の高音質。</p><p>1イベントで得られるサンプルの長さは`bufferSize`によって決まり、範囲は`256~16384`らしい（Chromeいわく）<br />\n引数を`0`にすると、ブラウザが自動で選んでくれる + それがおすすめらしい。</p>\n\n</div>\n<div class=\"section\">\n    <h4>AudioWorkletProcessor</h4>\n    <p>`ScriptProcessor`が非推奨になって、こっちを使えというやつ。</p><p>詳しいことは以下の記事を。<br />\nちょっと古いけど、状況は何も変わってなかったので・・。</p>\n\n    <blockquote>\n        <p><a href=\"https://lealog.hateblo.jp/entry/2019/01/17/150240\">AudioWorklet&#x306B;&#x3064;&#x3044;&#x3066;&#x8ABF;&#x3079;&#x305F;&#x30E1;&#x30E2; - console.lealog();</a></p>\n\n    </blockquote>\n<p>ただこのモダンなAPIは、Chromeでしか実装されておりません！</p><p>こっちは`process()`が呼ばれるたびに、チャンネルごとの`Float32Array(128)`が固定長で得られる。<br />\n呼ばれる頻度は変わらずサンプリングレートに依存していて、8000Hzの場合は`8000 / 128 = 62.5回/秒`くらい。</p><p>こっちは`AudioBuffer`ではなくただの`Float32Array`なので、`getChannelData()`とかできないので注意。</p><p>はやく普及してくれ〜〜。</p>\n\n</div>\n</div>\n<div class=\"section\">\n    <h3>WebRTCもどき（エンコード）</h3>\n    <p>OPUSやPCMUやFLACやらなんでもいいけど、独自にエンコードしたい場合。</p><p>基本的にはもう察しが付くと思いますが、`ScriptProcessor`か`AudioWorkletProcessor`で、PCMをエンコードして飛ばす。</p><p>`ScriptProcessor`ならメインスレッドにいるのでそのまま`WebSocket`などにつなげる。<br />\n単に`WebWorker`を作って、そっちにPCMを渡して、処理 + `WebSocket`で飛ばすのも手。</p><p>`AudioWorkletProcessor`は`AudioWorkletGlobalScope`にいるので、`WebSocket`がありません。<br />\nなので、`port`プロパティを使って`postMessage()`してメインスレッドに戻す必要がある。</p><p>そう考えると、この用途に`AudioWorkletProcessor`はあんまりいらなくて、単なる`WebWorker` + `ScriptProcessor`でいい説。</p><p>`WebWorker`でメインスレッドからPCMデータを受け取って、中でWASMを使ってエンコードして、メインスレッドへ返す or WebSocketで飛ばす。</p>\n\n</div>\n<div class=\"section\">\n    <h3>WebRTCもどき（デコード）</h3>\n    <p>実はコーデック次第では、`decodeAudioData()`でそのまま`AudioBuffer`にして再生できちゃう。</p><p>ブラウザが`audio`要素でそのまま再生できるような`mp3`とか`flac`とかそういったものなら。<br />\nMedia Capabilities APIとかで確認してもよいはず。</p><p>あとはそれを適当にキューイングしながら再生すればよい。</p><p>自分でデコードする場合は、送信側と受信側でサンプルレートをあわせることをお忘れなく。</p>\n\n</div>\n<div class=\"section\">\n    <h3>おまけ: 他にわかったこと</h3>\n    \n<div class=\"section\">\n    <h4>AudioNodeの作成</h4>\n    <pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synStatement\">const</span> ctx = <span class=\"synStatement\">new</span> AudioContext();\n\n<span class=\"synComment\">// old</span>\n<span class=\"synStatement\">const</span> gain = ctx.createGain();\ngain.gain.value = 0;\n\n<span class=\"synComment\">// new</span>\n<span class=\"synStatement\">const</span> gain = <span class=\"synStatement\">new</span> GainNode(ctx, <span class=\"synIdentifier\">{</span> gain: 0 <span class=\"synIdentifier\">}</span>)\n</pre><p>みたく、各コンストラクタから直接つくれる。Chromeなら。</p>\n\n</div>\n<div class=\"section\">\n    <h4>AudioNodeの接続</h4>\n    <pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synComment\">// old</span>\nsourceNode.connect(compNode);\ncompNode.connect(gainNode);\ngainNode.connect(ctx.destination);\n\n<span class=\"synComment\">// new</span>\nsourceNode\n  .connect(compNode)\n  .connect(gainNode)\n  .connect(ctx.destination);\n</pre><p>まぁ複数つなぎたい場合は困るけど、1本ならシュッと書ける。</p>\n\n</div>\n<div class=\"section\">\n    <h4>sampleRate</h4>\n    <p>最近のモダンブラウザは、だいたいデフォルトで`48000`です。</p><p>ただし、iOSのSafariだけは、`44100`だった。<br />\nかつ、Safariは`sampleRate`の指定ができないので、他の環境で指定して合わせる必要がある。</p><p>macのSafari x iOSのSafariを独自につなげたい場合は、リサンプラーを実装する必要がある・・。</p>\n\n</div>\n<div class=\"section\">\n    <h4>OfflineAudioContext</h4>\n    <p>使ったことないけど、一気にダウンサンプリングしたいときなどに有用らしい。</p>\n<pre class=\"code lang-javascript\" data-lang=\"javascript\" data-unlink><span class=\"synComment\">// Chrome, Firefox</span>\n<span class=\"synStatement\">new</span> OfflineAudioContext(<span class=\"synIdentifier\">{</span> channels: 1, length: 10, sampleRate: 48000 <span class=\"synIdentifier\">}</span>);\n<span class=\"synComment\">// Safari</span>\n<span class=\"synStatement\">new</span> webkitOfflineAudioContext(1, 10, 48000);\n</pre><p>引数がぜんぜん違うとSOで話題だった。</p>\n\n</div>\n<div class=\"section\">\n    <h4>ConstantSourceNode</h4>\n    <p>入力としてのPCMはいらないけど、決まったレートで`AudioWorkletProcessor `を動かしたいときとかに便利。</p>\n\n</div>\n</div>"
}
