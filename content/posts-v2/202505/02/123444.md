---
title: Letters from Andrew Ng / Agentic Design Patterns のまとめ
---

Courseraの機械学習コースでもお世話になったAndrew先生のありがたい記事を見つけたので。

> Four AI Agent Strategies That Improve GPT-4 and GPT-3.5 Performance
> https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/

この記事からはじまった一連のシリーズ（全5記事）のまとめ。

これらが公開されたのはもう1年も前の話やし、今ならAIにまとめ作ってって言えば10秒で全記事まとめてくれるけど、それでも自分で読んでおきたいなと。

全自動はやっぱりなんだか味気ないし、今だからこそちゃんと理解できる内容もあるやろうし。

## Part 1

> https://www.deeplearning.ai/the-batch/how-agents-can-improve-llm-performance/

- 昨今のLLMは、0-shotで使われることが多い
  - 1プロンプトだけを投げて、そこから答えを得ようとすること
- それでも期待以上の結果にはなってるのがまずすごい
- が、Agenticなワークフローを使えば、もっと正確な答えが出せる
- たとえば、
  - アウトラインを先に作って
  - TODOを定め、どういうToolを使うか決めたり
  - まずは初稿としての答えを生成し
  - それをセルフレビューして、間違いを修正する
  - などなど
- Devinがその例で、自律的に動作するAgentの可能性が注目されてる
- そんなAgenticなワークフローを、4種類に分けて紹介していくよ
  - Reflection: 自分で自分の答えを反芻する
  - Tool Use: Web検索やコマンド・コード実行など、情報を集めたり行動を起こしたり
  - Planning: ゴールを達成するために、必要なステップを洗い出してく
  - Multi-agent: 複数のAgentと協働して、タスクを分割したり相互レビューしたり

今なら言ってることもわかるし、確かにそうですよねってなれる。

## Part 2

> https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/

- まずはReflectionという手法について
- これは、あなたが普段やってるLLMとの会話と同じ
  - LLMからの回答に対して、フィードバックをしてるはず
- それを、自動的に内省させられないか？ということ
- 最初の回答と、それをレビューして改善してっていう追加のプロンプトをコンテキストに渡す
- これはコード生成以外の場面にも使える
- 成果物に対して、LinterやユニットテストなどのToolを使わせることも有効
- メインのAgentと、それをレビューする担当のAgentと2つ使うのもよい
- より深くこの手法を学びたいなら、以下の論文がおすすめ
  - Self-Refine: Iterative Refinement with Self-Feedback: https://arxiv.org/abs/2303.17651
  - Reflexion: Language Agents with Verbal Reinforcement Learning: https://arxiv.org/abs/2303.11366
  - CRITIC: Large Language Models Can Self-Correct with Tool-Interactive Critiquing: https://arxiv.org/abs/2305.11738

なるほどな〜。

NvimのプラグインでLLMを使える`avante.nvim`ってのがあって、その設定に`dual_boost`っていう、正にこれをやるためのオプションがあったの思い出した。

> https://github.com/yetone/avante.nvim/blob/555b2e615c47f1587b21a05c9cae6c48537146a7/lua/avante/config.lua#L355

## Part 3

> https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/

- Tool Useという手法について
  - Web検索もしてくれるLLMなんかが最たる例ではあるが、もっといろんな可能性がある
- 特定の分野に詳しいAIを作るためには、これまではその分野を事前学習させたりしてたけど、その限界にも気付きつつあった
- それよりも、Toolを使って外部から得た知識をコンテキストに取り込むほうが、汎用性もあるし、期待した結果も得られる 
- たとえば計算問題を与えたときに、内部的にTransformerで導出するより、実際にコードに落とし込んで実行するように
- この分野はすごく開拓が進んでいて、今では本当にいろんなことができる
  - あらゆるソースを検索し、メール送信だけでなく数多のAPIを実行したり、画像生成までできる
- 利用可能なToolのリストと、概要やそのインターフェースなどを渡すだけでいい
- もちろんToolの数が増えれば増えるほど、それをコンテキストにどこまで載せるか？を判断する必要は出てくる
  - Toolは無限にあるかもしれないが、その全てが今必要ではないし、コンテキストは有限
  - RAGでやってたように、最初に親和性の高いTool群を選ぶようにするとか
- 今ではマルチモーダルなLLMも多いけど、当初は画像を扱うのに苦労したものである
- GPT-4のFunction callingから一気に一般化した手法
- 興味があるなら以下の論文を
  - Gorilla: Large Language Model Connected with Massive APIs: https://arxiv.org/abs/2305.15334
  - MM-REACT: Prompting ChatGPT for Multimodal Reasoning and Action: https://arxiv.org/abs/2303.11381
  - Efficient Tool Use with Chain-of-Abstraction Reasoning: https://arxiv.org/abs/2401.17464
- ReflectionとTool Useは、効果も安定したとてもよい手法なので、ぜひ取り入れるといい
  - 追って紹介する残り2つの手法はまだ成熟してないけど

MCPやん！ってなった。
それに必要なMCPだけを選びとるステップ欲しいよな〜って思ってたところよ。

## Part 4

> https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/

- Planningは、より規模の大きいタスクに取り組む際に有用な手法
  - 目的を達成するために、ステップを小分けにしてく
- 複数のWeb検索を行うAgentを作ってデモをしていたときの体験
  - とあるAPIがレート制限にかかって、デモが失敗するかと思った
  - するとAIは、そのAPIの代わりにWikipediaの検索に自動的にフォールバックした
  - ことなきを得たと同時に、AIの進化に驚いた
- 多くのタスクは、単一のステップや単一のToolでは達成できないので、それを分割する
- たとえば、男の子の写真を提示して、同じポーズで女の子の写真を生成したいとする
  - このとき、まずは男の子のポーズを解析して
  - その上で、解析したポーズから女の子の写真を生成する
- Planningは、すべてのタスクに必須というわけではない
  - ゴールが明確な場合は、その処理も決定論的であり、複数回の反芻だけで済むから
- 非常に強力な手法である一方で、予測不能な結果を生み出しがちでもある
  - これから改善されていくと思うが、ReflectionやTool Useほど確かな手応えはまだない
- この分野に詳しい論文はこちら
  - Chain-of-Thought Prompting Elicits Reasoning in Large Language Models: https://arxiv.org/abs/2201.11903
  - HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face: https://arxiv.org/abs/2303.17580
  - Understanding the planning of LLM agents: A survey: https://arxiv.org/pdf/2402.02716

さすが先生といった感じ。現時点でも、Planningはまだ人間がやる方がいいなと思ってたりするので。

予測不能になりがちというのも納得で、ClaudeCodeとかがどんどんどツボにハマっていくのを眺める時のアレやんってなった。

## Part 5

> https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/

- 最後に、Multi-agentという手法
  - たとえば、サービスを構築するために、エンジニア、PM、デザイナーなどそれぞれの役職に見立てたAgentを協働させる
- 単一のLLMに対して、役割を指示するプロンプトを与えて使い分ければよい
- 最近のLLMは長大なコンテキストを入力できるが、その全てを的確に解釈できるわけではない
  - 役割を分けるほうがよい結果になるし、個別の最適化もできる
- このAgent分割を通して、我々が具体的なタスクの分割に取り組むことができるのも大事なポイント
- そもそも今までも人間のリーダーが、事業を分野に分けて、必要な人材を登用してきたのと同じ
- それぞれのAgentが引き続きPlanningやToolを使うこともできるので、より複雑なワークフローになるのは必然
  - もちろん思いがけない方向に進んでしまうことも
- 人間をマネジメントするのが大変なように、Agentをマネジメントするのももちろん大変
  - ただ、間違えても人間のように病んだりしないのはポイント
- この分野を掘り下げるなら、ChatDevを見てみるとよい
  - https://github.com/OpenBMB/ChatDev
  - 架空のソフトウェア開発会社で、複数の役割のAgentを協働して開発させられる
- Planningよりも振れ幅が大きくて予測できない手法ではあるけど
- この手法についてのおすすめ論文はこちら
  - ChatDev: Communicative Agents for Software Development: https://arxiv.org/abs/2307.07924
  - AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation: https://arxiv.org/abs/2308.08155
  - MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework: https://arxiv.org/abs/2308.00352

ChatDev、GitHubのREADMEに貼ってある動画をみるだけでも結構おもしろい。

## 感想

という予測があってこその、この2025年の今か〜っていうのが実感できてよかった。

こういう手法がある上で、それらをどうやってツールやインターフェースに落とし込んで提供するかってところが、昨今のAI活用って感じかね。

いろんなツールが日々出てきてるけど、その内部で何が行われてるのかをきちんと理解しておくことは、やはりいつの時代でも有効なのだなあ。

