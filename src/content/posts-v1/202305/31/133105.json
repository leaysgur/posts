{
  "title": "TensorFlow.jsのUniversal Sentence Encoderで、ブラウザ上でEmbeddingsを作る",
  "html": "<p>ということをやってみた。</p><p>できたにはできた、が・・・、って感想だった。<br />\n<br />\n</p>\n\n<div class=\"section\">\n    <h3 id=\"モチベーション\">モチベーション</h3>\n    \n    <blockquote>\n        <p><a href=\"https://lealog.hateblo.jp/entry/2023/04/17/103002\">OpenAI&#x306E;Embeddings&#x3067;&#x5168;&#x6587;&#x691C;&#x7D22; - console.lealog();</a></p>\n\n    </blockquote>\n<p>前に、OpenAIの<a class=\"keyword\" href=\"https://d.hatena.ne.jp/keyword/API\">API</a>を使って、テキストの特徴を表すEmbeddingsを作ってた。</p><p>で、1536次元のベクトルはなかなかの精度で良いものの・・・、</p>\n\n<ul>\n<li><a class=\"keyword\" href=\"https://d.hatena.ne.jp/keyword/API\">API</a>経由なので大量作成が手間</li>\n<li>それぞれのサイズも結構でかい（<a class=\"keyword\" href=\"https://d.hatena.ne.jp/keyword/JSON\">JSON</a>にすると25KBくらい）</li>\n<li>お金もかかる</li>\n</ul><p>っていうところで、ブラウザで動くモデルがあれば、もっと手軽にできるのでは？！という。</p>\n\n</div>\n<div class=\"section\">\n    <h3 id=\"ブラウザで動くモデルを探す\">ブラウザで動くモデルを探す</h3>\n    <p>Embeddingsを作りたいのは、<a class=\"keyword\" href=\"https://d.hatena.ne.jp/keyword/%BC%AB%C1%B3%B8%C0%B8%EC\">自然言語</a>による検索に利用したいから。<br />\nとなると、検索クエリもEmbeddingsにする必要があり、それをやれる場所となるとブラウザかCloudflare Workersになる、まずはサイズに縛られないブラウザで、という縛りで。</p><p>あれこれ探してみたものの、これだ！っていうのはそうそう見つからず。なんとか見つけて動かせたのが、Tensorflow.jsのUniversal Sentence Encoderを使った実装だったというわけ。</p>\n\n    <blockquote>\n        <p><a href=\"https://github.com/tensorflow/tfjs-models/tree/master/universal-sentence-encoder/\">tfjs-models/universal-sentence-encoder at master &middot; tensorflow/tfjs-models &middot; GitHub</a></p>\n\n    </blockquote>\n\n</div>\n<div class=\"section\">\n    <h3 id=\"やってみた\">やってみた</h3>\n    \n    <blockquote>\n        <p><a href=\"https://github.com/leader22/tfjs-embeddings-by-use\">GitHub - leader22/tfjs-embeddings-by-use: Playground for embeddings by Tensorflow.js Universal Sentence Encoder</a></p>\n\n    </blockquote>\n<p><a class=\"keyword\" href=\"https://d.hatena.ne.jp/keyword/GitHub\">GitHub</a> Pagesにもアップロードしてあるので、誰でも試せるようになってます（が、通信料に注意）。</p>\n\n<ul>\n<li>Viteでビルドしていて</li>\n<li>TensorFlow.js関連は遅延ロードさせてある\n<ul>\n<li>ガワだけで230KBもあるし、モデルは28MBとかある</li>\n</ul></li>\n<li>ロード後、テキストを入力するとEmbeddingsにその場で変換</li>\n<li>2つ以上のEmbeddingsがあれば、それらのコサイン類似度を計算</li>\n</ul><p>って感じ。</p><p>2015年の古いMBPでも、1件あたり1秒くらいで512次元のベクトルにしてくれる。</p>\n\n</div>\n<div class=\"section\">\n    <h3 id=\"結果に関して\">結果に関して</h3>\n    <p>元リポでも提示されてるような、英語に関する類似度はそれっぽい結果になる。</p><p><blockquote data-conversation=\"none\" class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"ja\" dir=\"ltr\">ふ〜む <a href=\"https://t.co/g8KKjc0ny5\">pic.twitter.com/g8KKjc0ny5</a></p>&mdash; りぃ / Yuji Sugiura (@leader22) <a href=\"https://twitter.com/leader22/status/1663764298831921152?ref_src=twsrc%5Etfw\">May 31, 2023</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script> </p><br />\n<p>けど、日本語にすると精度はもちろん良くないし、本来の目的である技術系のコンテキストも汲んでくれてるとは思えなかった。</p><p>でもまぁ元のモデルも学習データも英語のみが対象で、OpenAIのそれに比べるとモデルのサイズも小さいし、当然といえば当然か。</p><p>ちなみに、デフォルトで使われるモデルはコレだそうな。</p>\n\n    <blockquote>\n        <p><a href=\"https://tfhub.dev/tensorflow/tfjs-model/universal-sentence-encoder-lite/1/default/1\">https://tfhub.dev/tensorflow/tfjs-model/universal-sentence-encoder-lite/1/default/1</a></p>\n\n    </blockquote>\n<p><a class=\"keyword\" href=\"https://d.hatena.ne.jp/keyword/API\">API</a>としては他のモデルも使える風になってたけど、何をどう指定してもどこかでエラーになってうまくいかなかった。修行が足りぬ。</p>\n\n</div>"
}
